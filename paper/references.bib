@article{balki2019,
	author = {Indranil Balki and Afsaneh Amirabadi and Jacob Levman and Anne L. Martel and Ziga Emersic and Blaz Meden and Angel Garcia-Pedrero and Saul C. Ramirez and Dehan Kong and Alan R. Moody and Pascal N. Tyrrell},
	journal = {Canadian Association of Radiologists Journal},
    title = {Sample-Size Determination Methodologies for Machine Learning in Medical Imaging Research: A Systematic Review},
	number = {4},
	pages = {344-353},
	volume = {70},
	year = {2019}
}

@article{baum1989,
    author = {Baum,  Eric B. and Haussler,  David},
    title = {What Size Net Gives Valid Generalization?},
    journal = {Neural Computation},
    publisher = {MIT Press - Journals},
    DOI = {10.1162/neco.1989.1.1.151},
    number = {1},
    pages = {151–160},
    volume = {1},
    year = {1989},
    month = mar,   
}

@book{vapnik2000,
    title = {The Nature of Statistical Learning Theory},
    ISBN = {9781475732641},
    url = {http://dx.doi.org/10.1007/978-1-4757-3264-1},
    DOI = {10.1007/978-1-4757-3264-1},
    publisher = {Springer New York},
    author = {Vapnik,  Vladimir N.},
    year = {2000}
}

@article{rokem2017,
    title={Assessment of the need for separate test set and number of medical images necessary for deep learning: a sub-sampling study},
    author={Ariel S. Rokem and Yue Wu and Aaron Lee},
    journal={bioRxiv},
    year={2017},
    url={https://api.semanticscholar.org/CorpusID:67741678}
}

@misc{cho2016,
    title={How much data is needed to train a medical image deep learning system to achieve necessary high accuracy?}, 
    author={Junghwan Cho and Kyewook Lee and Ellie Shin and Garry Choy and Synho Do},
    year={2016},
    eprint={1511.06348},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{sagun2017eigenvalues,
      title={Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond}, 
      author={Levent Sagun and Leon Bottou and Yann LeCun},
      year={2017},
      eprint={1611.07476},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{papyan2019spectrum,
      title={The Full Spectrum of Deepnet Hessians at Scale: Dynamics with SGD Training and Sample Size}, 
      author={Vardan Papyan},
      year={2019},
      eprint={1811.07062},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{papyan2019measurements,
      title={Measurements of Three-Level Hierarchical Structure in the Outliers in the Spectrum of Deepnet Hessians}, 
      author={Vardan Papyan},
      year={2019},
      eprint={1901.08244},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wu2022dissecting,
      title={Dissecting Hessian: Understanding Common Structure of Hessian in Neural Networks}, 
      author={Yikai Wu and Xingyu Zhu and Chenwei Wu and Annie Wang and Rong Ge},
      year={2022},
      eprint={2010.04261},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{fort2019emergent,
      title={Emergent properties of the local geometry of neural loss landscapes}, 
      author={Stanislav Fort and Surya Ganguli},
      year={2019},
      eprint={1910.05929},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{NEURIPS2018_5a4be1fa,
	author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
	booktitle = {Advances in Neural Information Processing Systems},
	title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
	volume = {31},
	year = {2018}}


@article{Lee_2020,
	author = {Jaehoon Lee and Lechao Xiao and Samuel S Schoenholz and Yasaman Bahri and Roman Novak and Jascha Sohl-Dickstein and Jeffrey Pennington},
	doi = {10.1088/1742-5468/abc62b},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	month = {dec},
	number = {12},
	pages = {124002},
	publisher = {IOP Publishing and SISSA},
	title = {Wide neural networks of any depth evolve as linear models under gradient descent*},
	url = {https://dx.doi.org/10.1088/1742-5468/abc62b},
	volume = {2020},
	year = {2020}}

@misc{singla2019understanding,
      title={Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation}, 
      author={Sahil Singla and Eric Wallace and Shi Feng and Soheil Feizi},
      year={2019},
      eprint={1902.00407},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{ju2023robustfinetuningdeepneural,
      title={Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees}, 
      author={Haotian Ju and Dongyue Li and Hongyang R. Zhang},
      year={2023},
      eprint={2206.02659},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.02659}, 
}

@misc{nguyen2024agnosticsharpnessawareminimization,
      title={Agnostic Sharpness-Aware Minimization}, 
      author={Van-Anh Nguyen and Quyen Tran and Tuan Truong and Thanh-Toan Do and Dinh Phung and Trung Le},
      year={2024},
      eprint={2406.07107},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.07107}, 
}

@misc{macdonald2023progressivesharpeningflatminima,
      title={On progressive sharpening, flat minima and generalisation}, 
      author={Lachlan Ewen MacDonald and Jack Valmadre and Simon Lucey},
      year={2023},
      eprint={2305.14683},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14683}, 
}

@misc{sagun2017eigenvalueshessiandeeplearning,
      title={Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond}, 
      author={Levent Sagun and Leon Bottou and Yann LeCun},
      year={2017},
      eprint={1611.07476},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1611.07476}, 
}

@misc{sagun2018empiricalanalysishessianoverparametrized,
      title={Empirical Analysis of the Hessian of Over-Parametrized Neural Networks}, 
      author={Levent Sagun and Utku Evci and V. Ugur Guney and Yann Dauphin and Leon Bottou},
      year={2018},
      eprint={1706.04454},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1706.04454}, 
}


@InProceedings{pmlr-v70-pennington17a,
  title = 	 {Geometry of Neural Network Loss Surfaces via Random Matrix Theory},
  author =       {Jeffrey Pennington and Yasaman Bahri},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2798--2806},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/pennington17a/pennington17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/pennington17a.html}
}


@InProceedings{pmlr-v97-ghorbani19b,
  title = 	 {An Investigation into Neural Net Optimization via Hessian Eigenvalue Density},
  author =       {Ghorbani, Behrooz and Krishnan, Shankar and Xiao, Ying},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2232--2241},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/ghorbani19b/ghorbani19b.pdf},
  url = 	 {https://proceedings.mlr.press/v97/ghorbani19b.html}
}

@misc{wu2022dissectinghessianunderstandingcommon,
      title={Dissecting Hessian: Understanding Common Structure of Hessian in Neural Networks}, 
      author={Yikai Wu and Xingyu Zhu and Chenwei Wu and Annie Wang and Rong Ge},
      year={2022},
      eprint={2010.04261},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2010.04261}, 
}

@misc{singh2023hessianperspectivenatureconvolutional,
      title={The Hessian perspective into the Nature of Convolutional Neural Networks}, 
      author={Sidak Pal Singh and Thomas Hofmann and Bernhard Schölkopf},
      year={2023},
      eprint={2305.09088},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.09088}, 
}

@misc{singh2021analyticinsightsstructurerank,
      title={Analytic Insights into Structure and Rank of Neural Network Hessian Maps}, 
      author={Sidak Pal Singh and Gregor Bachmann and Thomas Hofmann},
      year={2021},
      eprint={2106.16225},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.16225}, 
}

@misc{skorski2019chainruleshessianhigher,
      title={Chain Rules for Hessian and Higher Derivatives Made Easy by Tensor Calculus}, 
      author={Maciej Skorski},
      year={2019},
      eprint={1911.13292},
      archivePrefix={arXiv},
      primaryClass={cs.SC},
      url={https://arxiv.org/abs/1911.13292}, 
}

@misc{liao2021hessianeigenspectrarealisticnonlinear,
      title={Hessian Eigenspectra of More Realistic Nonlinear Models}, 
      author={Zhenyu Liao and Michael W. Mahoney},
      year={2021},
      eprint={2103.01519},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2103.01519}, 
}

@misc{dauphin2024neglectedhessiancomponentexplains,
      title={Neglected Hessian component explains mysteries in Sharpness regularization}, 
      author={Yann N. Dauphin and Atish Agarwala and Hossein Mobahi},
      year={2024},
      eprint={2401.10809},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.10809}, 
}

@misc{papyan2020tracesclasscrossclassstructurepervade,
      title={Traces of Class/Cross-Class Structure Pervade Deep Learning Spectra}, 
      author={Vardan Papyan},
      year={2020},
      eprint={2008.11865},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2008.11865}, 
}

@misc{papyan2019spectrumdeepnethessiansscale,
      title={The Full Spectrum of Deepnet Hessians at Scale: Dynamics with SGD Training and Sample Size}, 
      author={Vardan Papyan},
      year={2019},
      eprint={1811.07062},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1811.07062}, 
}

@misc{papyan2019measurementsthreelevelhierarchicalstructure,
      title={Measurements of Three-Level Hierarchical Structure in the Outliers in the Spectrum of Deepnet Hessians}, 
      author={Vardan Papyan},
      year={2019},
      eprint={1901.08244},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1901.08244}, 
}

@misc{garrod2024unifyinglowdimensionalobservations,
      title={Unifying Low Dimensional Observations in Deep Learning Through the Deep Linear Unconstrained Feature Model}, 
      author={Connall Garrod and Jonathan P. Keating},
      year={2024},
      eprint={2404.06106},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.06106}, 
}

@misc{singh2024landscapinglinearmodeconnectivity,
      title={Landscaping Linear Mode Connectivity}, 
      author={Sidak Pal Singh and Linara Adilova and Michael Kamp and Asja Fischer and Bernhard Schölkopf and Thomas Hofmann},
      year={2024},
      eprint={2406.16300},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.16300}, 
}

@misc{singh2022phenomenologydoubledescentfinitewidth,
      title={Phenomenology of Double Descent in Finite-Width Neural Networks}, 
      author={Sidak Pal Singh and Aurelien Lucchi and Thomas Hofmann and Bernhard Schölkopf},
      year={2022},
      eprint={2203.07337},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2203.07337}, 
}

@misc{wang2023instabilitieslargelearningrate,
      title={The instabilities of large learning rate training: a loss landscape view}, 
      author={Lawrence Wang and Stephen Roberts},
      year={2023},
      eprint={2307.11948},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2307.11948}, 
}

@misc{xie2022powerlawhessianspectrumsdeep,
      title={On the Power-Law Hessian Spectrums in Deep Learning}, 
      author={Zeke Xie and Qian-Yuan Tang and Yunfeng Cai and Mingming Sun and Ping Li},
      year={2022},
      eprint={2201.13011},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2201.13011}, 
}

@misc{choi2020empiricalcomparisonsoptimizersdeep,
      title={On Empirical Comparisons of Optimizers for Deep Learning}, 
      author={Dami Choi and Christopher J. Shallue and Zachary Nado and Jaehoon Lee and Chris J. Maddison and George E. Dahl},
      year={2020},
      eprint={1910.05446},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.05446}, 
}

@article{Soydaner_2020,
   title={A Comparison of Optimization Algorithms for Deep Learning},
   volume={34},
   ISSN={1793-6381},
   url={http://dx.doi.org/10.1142/S0218001420520138},
   DOI={10.1142/s0218001420520138},
   number={13},
   journal={International Journal of Pattern Recognition and Artificial Intelligence},
   publisher={World Scientific Pub Co Pte Lt},
   author={Soydaner, Derya},
   year={2020},
   month=apr, pages={2052013} }

@misc{schmidt2021descendingcrowdedvalley,
      title={Descending through a Crowded Valley - Benchmarking Deep Learning Optimizers}, 
      author={Robin M. Schmidt and Frank Schneider and Philipp Hennig},
      year={2021},
      eprint={2007.01547},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.01547}, 
}

@inproceedings{
neyshabur2018the,
title={The role of over-parametrization in generalization of neural networks},
author={Behnam Neyshabur and Zhiyuan Li and Srinadh Bhojanapalli and Yann LeCun and Nathan Srebro},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=BygfghAcYX},
}

@misc{zou2019improvedanalysistrainingoverparameterized,
      title={An Improved Analysis of Training Over-parameterized Deep Neural Networks}, 
      author={Difan Zou and Quanquan Gu},
      year={2019},
      eprint={1906.04688},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1906.04688}, 
}

@misc{allenzhu2019convergencetheorydeeplearning,
      title={A Convergence Theory for Deep Learning via Over-Parameterization}, 
      author={Zeyuan Allen-Zhu and Yuanzhi Li and Zhao Song},
      year={2019},
      eprint={1811.03962},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1811.03962}, 
}

@misc{allenzhu2020learninggeneralizationoverparameterizedneural,
      title={Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers}, 
      author={Zeyuan Allen-Zhu and Yuanzhi Li and Yingyu Liang},
      year={2020},
      eprint={1811.04918},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1811.04918}, 
}

@misc{choromanska2015losssurfacesmultilayernetworks,
      title={The Loss Surfaces of Multilayer Networks}, 
      author={Anna Choromanska and Mikael Henaff and Michael Mathieu and Gérard Ben Arous and Yann LeCun},
      year={2015},
      eprint={1412.0233},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.0233}, 
}

@misc{you2017largebatchtrainingconvolutional,
      title={Large Batch Training of Convolutional Networks}, 
      author={Yang You and Igor Gitman and Boris Ginsburg},
      year={2017},
      eprint={1708.03888},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1708.03888}, 
}

@misc{li2018visualizinglosslandscapeneural,
      title={Visualizing the Loss Landscape of Neural Nets}, 
      author={Hao Li and Zheng Xu and Gavin Taylor and Christoph Studer and Tom Goldstein},
      year={2018},
      eprint={1712.09913},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1712.09913}, 
}


@inproceedings{NIPS1994_01882513,
	author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {G. Tesauro and D. Touretzky and T. Leen},
	publisher = {MIT Press},
	title = {SIMPLIFYING NEURAL NETS BY DISCOVERING FLAT MINIMA},
	volume = {7},
	year = {1994}}

@misc{neyshabur2017exploringgeneralizationdeeplearning,
      title={Exploring Generalization in Deep Learning}, 
      author={Behnam Neyshabur and Srinadh Bhojanapalli and David McAllester and Nathan Srebro},
      year={2017},
      eprint={1706.08947},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1706.08947}, 
}

@misc{dinh2017sharpminimageneralizedeep,
      title={Sharp Minima Can Generalize For Deep Nets}, 
      author={Laurent Dinh and Razvan Pascanu and Samy Bengio and Yoshua Bengio},
      year={2017},
      eprint={1703.04933},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1703.04933}, 
}

@misc{fort2019emergentpropertieslocalgeometry,
      title={Emergent properties of the local geometry of neural loss landscapes}, 
      author={Stanislav Fort and Surya Ganguli},
      year={2019},
      eprint={1910.05929},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.05929}, 
}

@incollection{pytorch,
    title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
    booktitle = {Advances in Neural Information Processing Systems 32},
    pages = {8024--8035},
    year = {2019},
    publisher = {Curran Associates, Inc.},
    url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{deng2012mnist,
  title={The mnist database of handwritten digit images for machine learning research},
  author={Deng, Li},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}

@InProceedings{adam,
  author    = {Kingma, Diederik and Ba, Jimmy},
  booktitle = {International Conference on Learning Representations (ICLR)},
  title     = {Adam: A Method for Stochastic Optimization},
  year      = {2015},
  address   = {San Diega, CA, USA},
  optmonth  = {12},
}

@misc{wu2020visual,
      title={Visual Transformers: Token-based Image Representation and Processing for Computer Vision}, 
      author={Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang and Zhicheng Yan and Masayoshi Tomizuka and Joseph Gonzalez and Kurt Keutzer and Peter Vajda},
      year={2020},
      eprint={2006.03677},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{xiao2017fashionmnistnovelimagedataset,
      title={Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms}, 
      author={Han Xiao and Kashif Rasul and Roland Vollgraf},
      year={2017},
      eprint={1708.07747},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1708.07747}, 
}

@inproceedings{krizhevsky2009learning,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Alex Krizhevsky},
  year={2009},
  url={https://api.semanticscholar.org/CorpusID:18268744}
}
